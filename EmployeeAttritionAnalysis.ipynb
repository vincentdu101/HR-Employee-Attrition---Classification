{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HR Employee Attrition Predictor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    " \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from matplotlib.colors import ListedColormap\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encodeOutputVariable(y):\n",
    "    labelencoder_Y_Origin = LabelEncoder()\n",
    "    y = labelencoder_Y_Origin.fit_transform(y.astype(str))\n",
    "    return y\n",
    "\n",
    "def encodeCategoricalData(X, index):\n",
    "    # encode categorical data\n",
    "    labelencoder_X_Origin = LabelEncoder()\n",
    "    X[:, index] = labelencoder_X_Origin.fit_transform(X[:, index].astype(str))\n",
    "    return X    \n",
    "\n",
    "def encodeHotEncoder(X, numberOfCategories):\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [numberOfCategories])\n",
    "    X = onehotencoder.fit_transform(X.astype(str)).toarray()  \n",
    "    X = X[:, 1:]\n",
    "    return X\n",
    "\n",
    "def minimumValues(train):\n",
    "    return [0 if math.isnan(x) else x for x in train]\n",
    "\n",
    "def minimumDelay(x):\n",
    "    return 0 if np.isnan(x) or x < 0 else x\n",
    "\n",
    "def outputPredictorResults(y_test, y_pred, title):\n",
    "    # output results for Neural network Classification\n",
    "    print(\"\\nFor\", title, \"Classification\")\n",
    "    print(\"Accuracy Score of Prediction : \", metrics.accuracy_score(y_test, y_pred) * 100)\n",
    "    print(\"\\nConfusion Matrix\")\n",
    "    print(pd.crosstab(y_test.ravel(), y_pred.ravel(), rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(\"Zero One Loss: \", metrics.zero_one_loss(y_test, y_pred))\n",
    "#     print(\"Log Loss:      \", metrics.log_loss(y_test, y_pred))\n",
    "#     print(\"ROC AUC Score: \", metrics.roc_auc_score(y_test, y_pred, average=\"micro\"))\n",
    "\n",
    "    \n",
    "def graphROCCurve(y_test, y_pred):    \n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = metrics.roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = metrics.auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[\"micro\"])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def graphFeaturesImportant(rf_classifier, dataset):\n",
    "    trace = go.Scatter(\n",
    "        y = rf_classifier.feature_importances_, \n",
    "        x = dataset.columns.values, mode = \"markers\",\n",
    "        marker = dict(\n",
    "            sizemode = \"diameter\", sizeref=1, size=13, \n",
    "            color=rf_classifier.feature_importances_, colorscale=\"Portland\",\n",
    "            showscale=True\n",
    "        ),\n",
    "        text = dataset.columns.values\n",
    "    )\n",
    "    data = [trace]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        autosize = True,\n",
    "        title = \"Random Forest Feature Importance\",\n",
    "        hovermode = \"closest\",\n",
    "        xaxis = dict(\n",
    "            ticklen=5, showgrid=True, zeroline=True, showline=True\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title=\"Feature Importance\", showgrid=True, zeroline=True,\n",
    "            ticklen=5, gridwidth=2\n",
    "        ),\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig)\n",
    "    \n",
    "# developing the Multi Layer Perceptron Neural Network\n",
    "def creatingNeuralNetworkPredictor(X_train, y_train, X_test, y_test, preprocess):\n",
    "    print(\"\\nNeural Network Classifier Section\")\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    # initialize the Multi Layer Perceptron Neural Network \n",
    "    mlp_classifier = MLPClassifier(solver=\"adam\", alpha=1e-5, max_iter=500,\n",
    "                               hidden_layer_sizes=(13, 13, 13))\n",
    "    \n",
    "#     oversampler = SMOTE(random_state=0)\n",
    "#     smote_X_train, smote_y_train = oversampler.fit_sample(X_train, y_train)\n",
    "    \n",
    "    # hook up the preprocess step with the classifier params and create the pipeline\n",
    "    model = make_pipeline(preprocess, mlp_classifier)\n",
    "    \n",
    "    # fitting the Multi Layer Perceptron to the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    mlp_y_pred = model.predict(X_test)\n",
    "    \n",
    "    # use the threshold of error to determine whether a prediction is valid\n",
    "#     mlp_y_pred = (mlp_y_pred > 0.5)\n",
    "    \n",
    "    # making the confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test.ravel(), mlp_y_pred.ravel())\n",
    "    \n",
    "    print(\"Training set Score: \", model.score(X_train, y_train))\n",
    "    print(\"Testing set Score: \", model.score(X_test, y_test))    \n",
    "    \n",
    "    # output results\n",
    "    outputPredictorResults(y_test, mlp_y_pred, \"Neural Network\")\n",
    "#     graphROCCurve(y_test, mlp_y_pred)\n",
    "    \n",
    "# developing the Random Forest Classifier\n",
    "def creatingRandomForestPredictor(X_train, y_train, X_test, y_test, preprocess):\n",
    "    print(\"\\nRandom Forest Classifier Section\")\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    # initialize the Multi Layer Perceptron Neural Network \n",
    "    random_forest_classifier = RandomForestClassifier(**{'n_jobs': -1,\n",
    "        'n_estimators': 800,\n",
    "        'warm_start': True, \n",
    "        'max_features': 0.3,\n",
    "        'max_depth': 9,\n",
    "        'min_samples_leaf': 2,\n",
    "        'max_features' : 'sqrt',\n",
    "        'random_state' : 0,\n",
    "        'verbose': 0\n",
    "                                                      })\n",
    "    \n",
    "#     oversampler = SMOTE(random_state=0)\n",
    "#     smote_X_train, smote_y_train = oversampler.fit_sample(X_train, y_train)\n",
    "    \n",
    "    # hook up the preprocess step with the classifier params and create the pipeline\n",
    "    model = make_pipeline(preprocess, random_forest_classifier)\n",
    "    \n",
    "    # fitting Random Forest to the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    rf_y_pred = model.predict(X_test)\n",
    "    \n",
    "    # use the threshold of error to determine whether a prediction is valid\n",
    "#     rf_y_pred = (rf_y_pred > 0.5)\n",
    "    \n",
    "    # making the confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test.ravel(), rf_y_pred.ravel())\n",
    "    \n",
    "    print(\"Training set Score: \", model.score(X_train, y_train))\n",
    "    print(\"Testing set Score: \", model.score(X_test, y_test))    \n",
    "    \n",
    "    # output results\n",
    "    outputPredictorResults(y_test, rf_y_pred, \"Random Forest\")\n",
    "#     graphFeaturesImportant(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing the data\n",
    "dataset = pd.read_csv(\"./data/employee_attrition.csv\")\n",
    "dataset.head()\n",
    "dataset = dataset.drop([\"YearsWithCurrManager\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using pd to have dataframe drop column by name\n",
    "# X = dataset.drop([\"YearsWithCurrManager\"], axis=1).values\n",
    "# X = np.delete(X, [1], axis=1)\n",
    "# y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py:751: DeprecationWarning:\n",
      "\n",
      "`make_column_transformer` now expects (transformer, columns) as input tuples instead of (columns, transformer). This has been introduced in v0.20.1. `make_column_transformer` will stop accepting the deprecated (columns, transformer) order in v0.22.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using ColumnTransformer only approach\n",
    "transformed_data = dataset.loc[:, dataset.columns != \"Attrition\"]\n",
    "X = transformed_data.values\n",
    "y = dataset.Attrition.values\n",
    "\n",
    "numerical_features = transformed_data.dtypes == \"int64\"\n",
    "categorical_features = ~numerical_features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "    (categorical_features, OneHotEncoder()),\n",
    "    (numerical_features, make_pipeline(SimpleImputer(), StandardScaler()))\n",
    ")\n",
    "# classifier = MLPClassifier(solver=\"adam\", alpha=1e-5, max_iter=500,\n",
    "#                                hidden_layer_sizes=(13, 13, 13))\n",
    "\n",
    "# random_forest_classifier = RandomForestClassifier(**{'n_jobs': -1,\n",
    "#         'n_estimators': 800,\n",
    "#         'warm_start': True, \n",
    "#         'max_features': 0.3,\n",
    "#         'max_depth': 9,\n",
    "#         'min_samples_leaf': 2,\n",
    "#         'max_features' : 'sqrt',\n",
    "#         'random_state' : 0,\n",
    "#         'verbose': 0\n",
    "#                                                       })\n",
    "# model = make_pipeline(preprocess, random_forest_classifier)\n",
    "# model.fit(Z_train, yz_train)\n",
    "# print(\"score \", model.score(Z_test, yz_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y = dataset.iloc[:, 1].values\n",
    "# # loop over dataframe header and index values\n",
    "# for i in enumerate(dataset.columns.values):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # encode categorical data - needs to be index because X is an array\n",
    "# X = encodeCategoricalData(X, 1)\n",
    "# X = encodeCategoricalData(X, 3)\n",
    "# X = encodeCategoricalData(X, 6)\n",
    "# X = encodeCategoricalData(X, 10)\n",
    "# X = encodeCategoricalData(X, 14)\n",
    "# X = encodeCategoricalData(X, 16)\n",
    "# X = encodeCategoricalData(X, 20)\n",
    "# X = encodeCategoricalData(X, 21)\n",
    "\n",
    "# # remove dummy columns\n",
    "# X = encodeHotEncoder(X, 4)\n",
    "# print(\"Total\", len(X[0]), \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y = encodeOutputVariable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting the dataset into the training set and test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling \n",
    "# sc = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Info About the Dataset\n",
      "Does category contain null values?\n",
      "Age                         False\n",
      "Attrition                   False\n",
      "BusinessTravel              False\n",
      "DailyRate                   False\n",
      "Department                  False\n",
      "DistanceFromHome            False\n",
      "Education                   False\n",
      "EducationField              False\n",
      "EmployeeCount               False\n",
      "EmployeeNumber              False\n",
      "EnvironmentSatisfaction     False\n",
      "Gender                      False\n",
      "HourlyRate                  False\n",
      "JobInvolvement              False\n",
      "JobLevel                    False\n",
      "JobRole                     False\n",
      "JobSatisfaction             False\n",
      "MaritalStatus               False\n",
      "MonthlyIncome               False\n",
      "MonthlyRate                 False\n",
      "NumCompaniesWorked          False\n",
      "Over18                      False\n",
      "OverTime                    False\n",
      "PercentSalaryHike           False\n",
      "PerformanceRating           False\n",
      "RelationshipSatisfaction    False\n",
      "StandardHours               False\n",
      "StockOptionLevel            False\n",
      "TotalWorkingYears           False\n",
      "TrainingTimesLastYear       False\n",
      "WorkLifeBalance             False\n",
      "YearsAtCompany              False\n",
      "YearsInCurrentRole          False\n",
      "YearsSinceLastPromotion     False\n",
      "dtype: bool \n",
      "\n",
      "Said Yes to Attrition:  0\n",
      "Said No to Attrition:   0\n",
      "Total responses:        1470\n",
      "\n",
      "Neural Network Classifier Section\n",
      "---------------------------------\n",
      "Training set Score:  1.0\n",
      "Testing set Score:  0.8503401360544217\n",
      "\n",
      "For Neural Network Classification\n",
      "Accuracy Score of Prediction :  85.03401360544217\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted   No  Yes  All\n",
      "True                    \n",
      "No         334   21  355\n",
      "Yes         45   41   86\n",
      "All        379   62  441\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.88      0.94      0.91       355\n",
      "         Yes       0.66      0.48      0.55        86\n",
      "\n",
      "    accuracy                           0.85       441\n",
      "   macro avg       0.77      0.71      0.73       441\n",
      "weighted avg       0.84      0.85      0.84       441\n",
      "\n",
      "Zero One Loss:  0.1496598639455783\n",
      "\n",
      "Random Forest Classifier Section\n",
      "---------------------------------\n",
      "Training set Score:  0.9358600583090378\n",
      "Testing set Score:  0.8299319727891157\n",
      "\n",
      "For Random Forest Classification\n",
      "Accuracy Score of Prediction :  82.99319727891157\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted   No  Yes  All\n",
      "True                    \n",
      "No         354    1  355\n",
      "Yes         74   12   86\n",
      "All        428   13  441\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      1.00      0.90       355\n",
      "         Yes       0.92      0.14      0.24        86\n",
      "\n",
      "    accuracy                           0.83       441\n",
      "   macro avg       0.88      0.57      0.57       441\n",
      "weighted avg       0.85      0.83      0.78       441\n",
      "\n",
      "Zero One Loss:  0.17006802721088432\n"
     ]
    }
   ],
   "source": [
    "# outputting data summary\n",
    "print(\"Summary Info About the Dataset\")\n",
    "print(\"Does category contain null values?\")\n",
    "print(dataset.isnull().any(), \"\\n\")\n",
    "print(\"Said Yes to Attrition: \", y[(y == 1)].size)\n",
    "print(\"Said No to Attrition:  \", y[(y == 0)].size)\n",
    "print(\"Total responses:       \", y.size)\n",
    "\n",
    "creatingNeuralNetworkPredictor(X_train, y_train, X_test, y_test, preprocess)\n",
    "creatingRandomForestPredictor(X_train, y_train, X_test, y_test, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning:\n",
      "\n",
      "The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HR Employee Attrition Predictor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    " \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from matplotlib.colors import ListedColormap\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encodeOutputVariable(y):\n",
    "    labelencoder_Y_Origin = LabelEncoder()\n",
    "    y = labelencoder_Y_Origin.fit_transform(y.astype(str))\n",
    "    return y\n",
    "\n",
    "def encodeCategoricalData(X, index):\n",
    "    # encode categorical data\n",
    "    labelencoder_X_Origin = LabelEncoder()\n",
    "    X[:, index] = labelencoder_X_Origin.fit_transform(X[:, index].astype(str))\n",
    "    return X    \n",
    "\n",
    "def encodeHotEncoder(X, numberOfCategories):\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [numberOfCategories])\n",
    "    X = onehotencoder.fit_transform(X.astype(str)).toarray()  \n",
    "    X = X[:, 1:]\n",
    "    return X\n",
    "\n",
    "def minimumValues(train):\n",
    "    return [0 if math.isnan(x) else x for x in train]\n",
    "\n",
    "def minimumDelay(x):\n",
    "    return 0 if np.isnan(x) or x < 0 else x\n",
    "\n",
    "def outputPredictorResults(y_test, y_pred, title):\n",
    "    # output results for Neural network Classification\n",
    "    print(\"\\nFor\", title, \"Classification\")\n",
    "    print(\"Accuracy Score of Prediction : \", metrics.accuracy_score(y_test, y_pred) * 100)\n",
    "    print(\"\\nConfusion Matrix\")\n",
    "    print(pd.crosstab(y_test.ravel(), y_pred.ravel(), rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(\"Zero One Loss: \", metrics.zero_one_loss(y_test, y_pred))\n",
    "    print(\"Log Loss:      \", metrics.log_loss(y_test, y_pred))\n",
    "    print(\"ROC AUC Score: \", metrics.roc_auc_score(y_test, y_pred, average=\"micro\"))\n",
    "    graphROCCurve(y_test, y_pred, y)\n",
    "    \n",
    "def graphROCCurve(y_test, y_pred, y):    \n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = metrics.roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = metrics.auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[\"micro\"])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def graphFeaturesImportant(rf_classifier, dataset):\n",
    "    trace = go.Scatter(\n",
    "        y = rf_classifier.feature_importances_, \n",
    "        x = dataset.columns.values, mode = \"markers\",\n",
    "        marker = dict(\n",
    "            sizemode = \"diameter\", sizeref=1, size=13, \n",
    "            color=rf_classifier.feature_importances_, colorscale=\"Portland\",\n",
    "            showscale=True\n",
    "        ),\n",
    "        text = dataset.columns.values\n",
    "    )\n",
    "    data = [trace]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        autosize = True,\n",
    "        title = \"Random Forest Feature Importance\",\n",
    "        hovermode = \"closest\",\n",
    "        xaxis = dict(\n",
    "            ticklen=5, showgrid=True, zeroline=True, showline=True\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title=\"Feature Importance\", showgrid=True, zeroline=True,\n",
    "            ticklen=5, gridwidth=2\n",
    "        ),\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig)\n",
    "    \n",
    "# developing the Multi Layer Perceptron Neural Network\n",
    "def creatingNeuralNetworkPredictor(X_train, y_train, X_test, y_test, preprocess):\n",
    "    print(\"\\nNeural Network Classifier Section\")\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    # initialize the Multi Layer Perceptron Neural Network \n",
    "    mlp_classifier = MLPClassifier(solver=\"adam\", alpha=1e-5, max_iter=500,\n",
    "                               hidden_layer_sizes=(13, 13, 13))\n",
    "    \n",
    "#     oversampler = SMOTE(random_state=0)\n",
    "#     smote_X_train, smote_y_train = oversampler.fit_sample(X_train, y_train)\n",
    "    \n",
    "    # hook up the preprocess step with the classifier params and create the pipeline\n",
    "    model = make_pipeline(preprocess, mlp_classifier)\n",
    "    \n",
    "    # fitting the Multi Layer Perceptron to the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    mlp_y_pred = model.predict(X_test)\n",
    "    \n",
    "    # use the threshold of error to determine whether a prediction is valid\n",
    "    mlp_y_pred = (mlp_y_pred > 0.5)\n",
    "    \n",
    "    # making the confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test.ravel(), mlp_y_pred.ravel())\n",
    "    \n",
    "    print(\"Training set Score: \", model.score(X_train, y_train))\n",
    "    print(\"Testing set Score: \", model.score(X_test, y_test))    \n",
    "    \n",
    "    # output results\n",
    "    outputPredictorResults(y_test, mlp_y_pred, \"Neural Network\")\n",
    "    \n",
    "# developing the Random Forest Classifier\n",
    "def creatingRandomForestPredictor(X_train, y_train, X_test, y_test, preprocess):\n",
    "    print(\"\\nRandom Forest Classifier Section\")\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    # initialize the Multi Layer Perceptron Neural Network \n",
    "    random_forest_classifier = RandomForestClassifier(**{'n_jobs': -1,\n",
    "        'n_estimators': 800,\n",
    "        'warm_start': True, \n",
    "        'max_features': 0.3,\n",
    "        'max_depth': 9,\n",
    "        'min_samples_leaf': 2,\n",
    "        'max_features' : 'sqrt',\n",
    "        'random_state' : 0,\n",
    "        'verbose': 0\n",
    "                                                      })\n",
    "    \n",
    "#     oversampler = SMOTE(random_state=0)\n",
    "#     smote_X_train, smote_y_train = oversampler.fit_sample(X_train, y_train)\n",
    "    \n",
    "    # hook up the preprocess step with the classifier params and create the pipeline\n",
    "    model = make_pipeline(preprocess, random_forest_classifier)\n",
    "    \n",
    "    # fitting Random Forest to the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    rf_y_pred = model.predict(X_test)\n",
    "    \n",
    "    # use the threshold of error to determine whether a prediction is valid\n",
    "    rf_y_pred = (rf_y_pred > 0.5)\n",
    "    \n",
    "    # making the confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test.ravel(), rf_y_pred.ravel())\n",
    "    \n",
    "    print(\"Training set Score: \", model.score(X_train, y_train))\n",
    "    print(\"Testing set Score: \", model.score(X_test, y_test))    \n",
    "    \n",
    "    # output results\n",
    "    outputPredictorResults(y_test, rf_y_pred, \"Random Forest\")\n",
    "    graphFeaturesImportant(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing the data\n",
    "dataset = pd.read_csv(\"./data/employee_attrition.csv\")\n",
    "dataset.head()\n",
    "dataset = dataset.drop([\"YearsWithCurrManager\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using pd to have dataframe drop column by name\n",
    "# X = dataset.drop([\"YearsWithCurrManager\"], axis=1).values\n",
    "# X = np.delete(X, [1], axis=1)\n",
    "# y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py:751: DeprecationWarning:\n",
      "\n",
      "`make_column_transformer` now expects (transformer, columns) as input tuples instead of (columns, transformer). This has been introduced in v0.20.1. `make_column_transformer` will stop accepting the deprecated (columns, transformer) order in v0.22.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using ColumnTransformer only approach\n",
    "transformed_data = dataset.loc[:, dataset.columns != \"Attrition\"]\n",
    "X = transformed_data.values\n",
    "y = dataset.Attrition.values\n",
    "\n",
    "numerical_features = transformed_data.dtypes == \"int64\"\n",
    "categorical_features = ~numerical_features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "    (categorical_features, OneHotEncoder()),\n",
    "    (numerical_features, make_pipeline(SimpleImputer(), StandardScaler()))\n",
    ")\n",
    "# classifier = MLPClassifier(solver=\"adam\", alpha=1e-5, max_iter=500,\n",
    "#                                hidden_layer_sizes=(13, 13, 13))\n",
    "\n",
    "# random_forest_classifier = RandomForestClassifier(**{'n_jobs': -1,\n",
    "#         'n_estimators': 800,\n",
    "#         'warm_start': True, \n",
    "#         'max_features': 0.3,\n",
    "#         'max_depth': 9,\n",
    "#         'min_samples_leaf': 2,\n",
    "#         'max_features' : 'sqrt',\n",
    "#         'random_state' : 0,\n",
    "#         'verbose': 0\n",
    "#                                                       })\n",
    "# model = make_pipeline(preprocess, random_forest_classifier)\n",
    "# model.fit(Z_train, yz_train)\n",
    "# print(\"score \", model.score(Z_test, yz_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = dataset.iloc[:, 1].values\n",
    "# # loop over dataframe header and index values\n",
    "# for i in enumerate(dataset.columns.values):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # encode categorical data - needs to be index because X is an array\n",
    "# X = encodeCategoricalData(X, 1)\n",
    "# X = encodeCategoricalData(X, 3)\n",
    "# X = encodeCategoricalData(X, 6)\n",
    "# X = encodeCategoricalData(X, 10)\n",
    "# X = encodeCategoricalData(X, 14)\n",
    "# X = encodeCategoricalData(X, 16)\n",
    "# X = encodeCategoricalData(X, 20)\n",
    "# X = encodeCategoricalData(X, 21)\n",
    "\n",
    "# # remove dummy columns\n",
    "# X = encodeHotEncoder(X, 4)\n",
    "# print(\"Total\", len(X[0]), \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y = encodeOutputVariable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting the dataset into the training set and test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling \n",
    "# sc = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Info About the Dataset\n",
      "Does category contain null values?\n",
      "Age                         False\n",
      "Attrition                   False\n",
      "BusinessTravel              False\n",
      "DailyRate                   False\n",
      "Department                  False\n",
      "DistanceFromHome            False\n",
      "Education                   False\n",
      "EducationField              False\n",
      "EmployeeCount               False\n",
      "EmployeeNumber              False\n",
      "EnvironmentSatisfaction     False\n",
      "Gender                      False\n",
      "HourlyRate                  False\n",
      "JobInvolvement              False\n",
      "JobLevel                    False\n",
      "JobRole                     False\n",
      "JobSatisfaction             False\n",
      "MaritalStatus               False\n",
      "MonthlyIncome               False\n",
      "MonthlyRate                 False\n",
      "NumCompaniesWorked          False\n",
      "Over18                      False\n",
      "OverTime                    False\n",
      "PercentSalaryHike           False\n",
      "PerformanceRating           False\n",
      "RelationshipSatisfaction    False\n",
      "StandardHours               False\n",
      "StockOptionLevel            False\n",
      "TotalWorkingYears           False\n",
      "TrainingTimesLastYear       False\n",
      "WorkLifeBalance             False\n",
      "YearsAtCompany              False\n",
      "YearsInCurrentRole          False\n",
      "YearsSinceLastPromotion     False\n",
      "dtype: bool \n",
      "\n",
      "Said Yes to Attrition:  0\n",
      "Said No to Attrition:   0\n",
      "Total responses:        1470\n",
      "\n",
      "Neural Network Classifier Section\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'numpy.ndarray' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-452d93b83504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total responses:       \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcreatingNeuralNetworkPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcreatingRandomForestPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-4d1e925816f7>\u001b[0m in \u001b[0;36mcreatingNeuralNetworkPredictor\u001b[0;34m(X_train, y_train, X_test, y_test, preprocess)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# use the threshold of error to determine whether a prediction is valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mmlp_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmlp_y_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# making the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'numpy.ndarray' and 'float'"
     ]
    }
   ],
   "source": [
    "# outputting data summary\n",
    "print(\"Summary Info About the Dataset\")\n",
    "print(\"Does category contain null values?\")\n",
    "print(dataset.isnull().any(), \"\\n\")\n",
    "print(\"Said Yes to Attrition: \", y[(y == 1)].size)\n",
    "print(\"Said No to Attrition:  \", y[(y == 0)].size)\n",
    "print(\"Total responses:       \", y.size)\n",
    "\n",
    "creatingNeuralNetworkPredictor(X_train, y_train, X_test, y_test, preprocess)\n",
    "creatingRandomForestPredictor(X_train, y_train, X_test, y_test, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
